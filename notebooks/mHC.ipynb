{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-09T03:31:25.916677Z",
     "start_time": "2026-01-09T03:31:25.911681Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "bs, sl, expansion, dim = 2, 1, 4, 3\n",
    "X = torch.randn(bs, sl, dim)\n",
    "\n",
    "H_pre = torch.randn(expansion)\n",
    "X_pre = torch.einsum('bled,e->bd', X.unsqueeze(1).repeat(1, 1, expansion, 1), H_pre)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3193,  0.2545,  0.4482],\n",
       "        [-0.1236,  0.4518,  0.5052]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T08:20:07.496122Z",
     "start_time": "2026-01-09T08:20:07.491660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "H = torch.randn(bs, sl, dim).unsqueeze(-2).repeat(1, 1, expansion, 1)\n",
    "H"
   ],
   "id": "44aee6cd5464eb74",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.0768, -1.2149,  0.4028],\n",
       "          [ 1.0768, -1.2149,  0.4028],\n",
       "          [ 1.0768, -1.2149,  0.4028],\n",
       "          [ 1.0768, -1.2149,  0.4028]]],\n",
       "\n",
       "\n",
       "        [[[-0.2116,  0.9096, -0.2262],\n",
       "          [-0.2116,  0.9096, -0.2262],\n",
       "          [-0.2116,  0.9096, -0.2262],\n",
       "          [-0.2116,  0.9096, -0.2262]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T08:20:37.876923Z",
     "start_time": "2026-01-09T08:20:37.870992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HC(nn.Module):\n",
    "    def __init__(self, n, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.n = n\n",
    "        self.alpha = nn.Parameter(torch.zeros(n))\n",
    "        self.beta = nn.Parameter(torch.ones(n))\n",
    "        self.interaction = nn.Parameter(torch.eye(n, n))\n",
    "\n",
    "    def forward(self, H, layer):\n",
    "        res = torch.einsum('bled,ee->bled', H, self.interaction)\n",
    "        H = torch.einsum('bled,e->bld', H, self.alpha)\n",
    "        H = layer(H)\n",
    "        H = torch.einsum('bld,e->bled', H, self.beta)\n",
    "        return H + res\n",
    "\n",
    "hc = HC(expansion)\n",
    "hc(H, nn.Identity())"
   ],
   "id": "83ed4652e893d162",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.0768, -1.2149,  0.4028],\n",
       "          [ 1.0768, -1.2149,  0.4028],\n",
       "          [ 1.0768, -1.2149,  0.4028],\n",
       "          [ 1.0768, -1.2149,  0.4028]]],\n",
       "\n",
       "\n",
       "        [[[-0.2116,  0.9096, -0.2262],\n",
       "          [-0.2116,  0.9096, -0.2262],\n",
       "          [-0.2116,  0.9096, -0.2262],\n",
       "          [-0.2116,  0.9096, -0.2262]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T12:52:53.584885Z",
     "start_time": "2026-01-09T12:52:53.569170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn import LayerNorm\n",
    "\n",
    "class Sinkhorn(nn.Module):\n",
    "    def __init__(self, n_iters: int = 20, eps: float = 1e-8, temperature: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.n_iters = n_iters\n",
    "        self.eps = eps\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, H: torch.Tensor) -> torch.Tensor:\n",
    "        # H: (..., n_q, n_c) - arbitrary batch dimensions\n",
    "        K = (H * self.temperature).exp()\n",
    "        *batch_dims, n_q, n_c = K.shape\n",
    "\n",
    "        # Initialize scaling vectors with batch dimensions\n",
    "        u = torch.full((*batch_dims, n_q), 1.0 / n_q, device=K.device, dtype=K.dtype)\n",
    "        v = torch.full((*batch_dims, n_c), 1.0 / n_c, device=K.device, dtype=K.dtype)\n",
    "\n",
    "        # Sinkhornâ€“Knopp iterations using batched matrix operations\n",
    "        for _ in range(self.n_iters):\n",
    "            u = 1.0 / (torch.matmul(K, v.unsqueeze(-1)).squeeze(-1) + self.eps)\n",
    "            v = 1.0 / (torch.matmul(K.transpose(-2, -1), u.unsqueeze(-1)).squeeze(-1) + self.eps)\n",
    "\n",
    "        # Final doubly-stochastic matrix: diag(u) @ K @ diag(v)\n",
    "        return (u.unsqueeze(-1) * K) * v.unsqueeze(-2)\n",
    "\n",
    "class HyperConnection(nn.Module):\n",
    "    def __init__(self, dim, rate, layer_id, dynamic, device=None):\n",
    "        super(HyperConnection, self).__init__()\n",
    "\n",
    "        self.rate = rate\n",
    "        self.layer_id = layer_id\n",
    "        self.dynamic = dynamic\n",
    "\n",
    "        self.static_beta = nn.Parameter(torch.ones((rate,), device=device))\n",
    "\n",
    "        init_alpha0 = torch.zeros((rate, 1), device=device)\n",
    "        init_alpha0[layer_id % rate, 0] = 1.\n",
    "        self.static_alpha = nn.Parameter(torch.cat([init_alpha0, torch.eye((rate), device=device)], dim=1))\n",
    "\n",
    "        if self.dynamic:\n",
    "            self.dynamic_alpha_fn = nn.Parameter(torch.zeros((dim, rate+1), device=device))\n",
    "            self.dynamic_alpha_scale = nn.Parameter(torch.ones(1, device=device) * 0.01)\n",
    "            self.dynamic_beta_fn = nn.Parameter(torch.zeros((dim, ), device=device))\n",
    "            self.dynamic_beta_scale = nn.Parameter(torch.ones(1, device=device) * 0.01)\n",
    "            self.layer_norm = LayerNorm(dim)\n",
    "\n",
    "        self.ln = nn.LayerNorm(dim)\n",
    "        self.sinkhorn = Sinkhorn()\n",
    "\n",
    "    def forward(self, H, layer):\n",
    "        mix_h, beta = self.width_connection(H)\n",
    "        h = layer(self.ln(F.sigmoid(mix_h[..., 0, :])))\n",
    "        return self.depth_connection(mix_h, h, beta)\n",
    "\n",
    "    def width_connection(self, h):\n",
    "        # get alpha and beta\n",
    "        if self.dynamic:\n",
    "            norm_h = self.layer_norm(h)\n",
    "\n",
    "        if self.dynamic:\n",
    "            wc_weight = norm_h @ self.dynamic_alpha_fn\n",
    "            dynamic_alpha = wc_weight * self.dynamic_alpha_scale\n",
    "            alpha = dynamic_alpha + self.static_alpha[None, None, ...]\n",
    "        else:\n",
    "            alpha = self.static_alpha[None, None, ...]\n",
    "\n",
    "        if self.dynamic:\n",
    "            dc_weight = norm_h @ self.dynamic_beta_fn\n",
    "            dynamic_beta = dc_weight * self.dynamic_beta_scale\n",
    "            beta = dynamic_beta + self.static_beta[None, None, ...]\n",
    "        else:\n",
    "            beta = self.static_beta[None, None, ...]\n",
    "\n",
    "        # width connection\n",
    "        mix_h = alpha.transpose(-1, -2) @ h\n",
    "\n",
    "        return mix_h, beta\n",
    "\n",
    "    def depth_connection(self, mix_h, h_o, beta):\n",
    "        print(mix_h[..., 1:, :].shape)\n",
    "        h = 2 * F.sigmoid(torch.einsum(\"blh,bln->blnh\", h_o, beta)) + self.sinkhorn(mix_h[..., 1:, :])\n",
    "\n",
    "        return h\n",
    "\n",
    "hc = HyperConnection(dim, expansion, 0, dynamic=False, device='cpu')\n",
    "hc(H, nn.Identity())"
   ],
   "id": "5c1fa3d5326229f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.7186, 0.6586, 1.4199],\n",
       "          [1.7186, 0.6586, 1.4199],\n",
       "          [1.7186, 0.6586, 1.4199],\n",
       "          [1.7186, 0.6586, 1.4199]]],\n",
       "\n",
       "\n",
       "        [[[0.9169, 1.8587, 0.9043],\n",
       "          [0.9169, 1.8587, 0.9043],\n",
       "          [0.9169, 1.8587, 0.9043],\n",
       "          [0.9169, 1.8587, 0.9043]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1da0c6430403c762"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3526330ffea0a1aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
